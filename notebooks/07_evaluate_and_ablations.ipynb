{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 07 \u00b7 Evaluate and Run Ablations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Purpose\n\nMeasure retrieval quality and perform robustness checks on the unified pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inputs\n\n- `outputs/predictions/test.csv` (and optionally dev predictions).\n- `data/processed/artifacts_with_split.csv` with gold controls for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outputs\n\n- `eval/tables/metrics.csv` capturing aggregate and per-family metrics.\n- Notebook tables/plots summarizing ablation and leak-check findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps\n\n1. Compute Top-1, P@k, R@k, Jaccard@k (k \u2208 {1,3,5}), MAP, MRR, and per-family breakdowns.\n2. Verify partition integrity and surface sample comparisons of gold vs predictions.\n3. Re-run the duplicate text hash to ensure zero leakage across splits.\n4. Perform an adversarial label shuffle to confirm metrics collapse under label noise.\n5. Document additional ablations (e.g., w/o cross-encoder, w/o Auto-K) if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Acceptance Checks\n\n- `eval/tables/metrics.csv` is written with the required metrics.\n- Leak-check diagnostics (duplicates, partition coverage, random samples) are reported.\n- Ablation results and observations are captured in the notebook narrative."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
