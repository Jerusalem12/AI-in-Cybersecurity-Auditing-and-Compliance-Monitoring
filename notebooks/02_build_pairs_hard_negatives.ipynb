{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5976a805",
   "metadata": {},
   "source": [
    "# 02 · Build Pairs with Hard Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68721908",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "Construct supervised pairs with positives and BM25/TF-IDF hard negatives for ranking models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604a6d0",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "- `data/processed/controls_enhanced.csv` with rationale-augmented control descriptions.\n",
    "- `data/processed/artifacts_with_split.csv` produced by Notebook 01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecccdeaf",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "- `data/processed/pairs/train.jsonl`, `.../dev.jsonl`, and `.../test.jsonl` in the defined schema.\n",
    "- Optional diagnostics on positive/negative counts per split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4823f",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Create control index strings by concatenating title and summary (\"title. summary\").\n",
    "2. Instantiate a lexical retriever (BM25 or TF-IDF) over control texts.\n",
    "3. For each artifact, retrieve top-K candidate controls (e.g., 32) as hard-negative candidates.\n",
    "4. Emit labeled pairs: all gold controls as positives plus non-gold retrieved controls as negatives.\n",
    "5. Segment outputs by artifact partition and serialize to JSONL following the pair schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738609c7",
   "metadata": {},
   "source": [
    "## Acceptance Checks\n",
    "\n",
    "- No artifact from the test split appears in train or dev pair files.\n",
    "- Every train artifact yields at least one positive pair (label == 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "i7zf93ah7fh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:32.845508Z",
     "iopub.status.busy": "2025-10-26T02:19:32.845316Z",
     "iopub.status.idle": "2025-10-26T02:19:33.129055Z",
     "shell.execute_reply": "2025-10-26T02:19:33.128538Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nrgwf1b2ah",
   "metadata": {},
   "source": [
    "## 1. Load controls and artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5gwu2hp0ozn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:33.130553Z",
     "iopub.status.busy": "2025-10-26T02:19:33.130450Z",
     "iopub.status.idle": "2025-10-26T02:19:33.138985Z",
     "shell.execute_reply": "2025-10-26T02:19:33.138600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 34 enhanced controls\n",
      "  Sample control text: Account Management. Provision, review, and remove accounts; enforce least privilege and approvals.. ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>control_id</th>\n",
       "      <th>family</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>index_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC-2</td>\n",
       "      <td>AC</td>\n",
       "      <td>Account Management</td>\n",
       "      <td>Provision, review, and remove accounts; enforc...</td>\n",
       "      <td>Account Management. Provision, review, and rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC-6</td>\n",
       "      <td>AC</td>\n",
       "      <td>Least Privilege</td>\n",
       "      <td>Restrict privileges to the minimum necessary; ...</td>\n",
       "      <td>Least Privilege. Restrict privileges to the mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AC-7</td>\n",
       "      <td>AC</td>\n",
       "      <td>Unsuccessful Logon Attempts</td>\n",
       "      <td>Enforce lockout thresholds and durations after...</td>\n",
       "      <td>Unsuccessful Logon Attempts. Enforce lockout t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  control_id family                        title  \\\n",
       "0       AC-2     AC           Account Management   \n",
       "1       AC-6     AC              Least Privilege   \n",
       "2       AC-7     AC  Unsuccessful Logon Attempts   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Provision, review, and remove accounts; enforc...   \n",
       "1  Restrict privileges to the minimum necessary; ...   \n",
       "2  Enforce lockout thresholds and durations after...   \n",
       "\n",
       "                                          index_text  \n",
       "0  Account Management. Provision, review, and rem...  \n",
       "1  Least Privilege. Restrict privileges to the mi...  \n",
       "2  Unsuccessful Logon Attempts. Enforce lockout t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load enhanced controls\n",
    "controls = pd.read_csv(\"../data/processed/controls_enhanced.csv\", dtype=str)\n",
    "print(f\"✓ Loaded {len(controls)} enhanced controls\")\n",
    "\n",
    "# index_text is already created in controls_enhanced.csv\n",
    "print(f\"  Sample control text: {controls.iloc[0]['index_text'][:100]}...\")\n",
    "\n",
    "controls.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "xi1q9dm61ic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:33.140051Z",
     "iopub.status.busy": "2025-10-26T02:19:33.139978Z",
     "iopub.status.idle": "2025-10-26T02:19:33.147454Z",
     "shell.execute_reply": "2025-10-26T02:19:33.147095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 2574 artifacts\n",
      "  Partition distribution:\n",
      "partition\n",
      "dev       365\n",
      "test      354\n",
      "train    1855\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artifact_id</th>\n",
       "      <th>text</th>\n",
       "      <th>evidence_type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gold_controls</th>\n",
       "      <th>gold_rationale</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>User 'svc-api' failed login 11 times in 2 minu...</td>\n",
       "      <td>log</td>\n",
       "      <td>2025-09-15 08:15:00+00:00</td>\n",
       "      <td>AC-7;AU-6</td>\n",
       "      <td>Failed login threshold was met without a locko...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>Configuration scan shows object store bucket '...</td>\n",
       "      <td>config</td>\n",
       "      <td>2025-09-15 09:22:10+00:00</td>\n",
       "      <td>SC-28;SC-12</td>\n",
       "      <td>Information at rest is not encrypted and crypt...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>CHG-9901: Emergency hotfix for API memory leak...</td>\n",
       "      <td>ticket</td>\n",
       "      <td>2025-09-15 11:45:30+00:00</td>\n",
       "      <td>CM-3;SA-11</td>\n",
       "      <td>A configuration change was deployed without co...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artifact_id                                               text  \\\n",
       "0       10001  User 'svc-api' failed login 11 times in 2 minu...   \n",
       "1       10002  Configuration scan shows object store bucket '...   \n",
       "2       10003  CHG-9901: Emergency hotfix for API memory leak...   \n",
       "\n",
       "  evidence_type                  timestamp gold_controls  \\\n",
       "0           log  2025-09-15 08:15:00+00:00     AC-7;AU-6   \n",
       "1        config  2025-09-15 09:22:10+00:00   SC-28;SC-12   \n",
       "2        ticket  2025-09-15 11:45:30+00:00    CM-3;SA-11   \n",
       "\n",
       "                                      gold_rationale partition  \n",
       "0  Failed login threshold was met without a locko...     train  \n",
       "1  Information at rest is not encrypted and crypt...      test  \n",
       "2  A configuration change was deployed without co...     train  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load artifacts with splits\n",
    "artifacts = pd.read_csv(\"../data/processed/artifacts_with_split.csv\", dtype={\"artifact_id\": str, \"text\": str, \"evidence_type\": str, \"gold_controls\": str, \"partition\": str})\n",
    "\n",
    "print(f\"✓ Loaded {len(artifacts)} artifacts\")\n",
    "print(f\"  Partition distribution:\")\n",
    "print(artifacts[\"partition\"].value_counts().sort_index())\n",
    "\n",
    "artifacts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bj1xanxji",
   "metadata": {},
   "source": [
    "## 2. Build BM25 index over controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "m74ocw32uv",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:33.148335Z",
     "iopub.status.busy": "2025-10-26T02:19:33.148283Z",
     "iopub.status.idle": "2025-10-26T02:19:33.151089Z",
     "shell.execute_reply": "2025-10-26T02:19:33.150701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Built BM25 index over 34 controls\n",
      "\n",
      "  Test query: 'failed login attempts'\n",
      "  Top 3 controls:\n",
      "    1. AC-7: Unsuccessful Logon Attempts (score: 8.56)\n",
      "    2. AU-6: Audit Review, Analysis, and Reporting (score: 6.40)\n",
      "    3. SC-7: Boundary Protection (score: 1.89)\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Simple whitespace + lowercase tokenizer\"\"\"\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# Tokenize all control texts\n",
    "control_tokens = [tokenize(text) for text in controls[\"index_text\"]]\n",
    "\n",
    "# Build BM25 index\n",
    "bm25 = BM25Okapi(control_tokens)\n",
    "print(f\"✓ Built BM25 index over {len(control_tokens)} controls\")\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"failed login attempts\"\n",
    "test_scores = bm25.get_scores(tokenize(test_query))\n",
    "top_idx = np.argsort(test_scores)[::-1][:3]\n",
    "print(f\"\\n  Test query: '{test_query}'\")\n",
    "print(f\"  Top 3 controls:\")\n",
    "for i, idx in enumerate(top_idx):\n",
    "    print(f\"    {i+1}. {controls.iloc[idx]['control_id']}: {controls.iloc[idx]['title']} (score: {test_scores[idx]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "djv8mvk2vtf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved BM25 index to ../models/bm25/bm25_index.pkl\n",
      "  Size: 56.08 KB\n"
     ]
    }
   ],
   "source": [
    "# Save BM25 index and control data for later use\n",
    "import pickle\n",
    "\n",
    "bm25_dir = Path(\"../models/bm25\")\n",
    "bm25_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save BM25 index and related data\n",
    "bm25_data = {\n",
    "    \"bm25\": bm25,\n",
    "    \"control_tokens\": control_tokens,\n",
    "    \"control_ids\": controls[\"control_id\"].tolist(),\n",
    "    \"control_texts\": controls[\"index_text\"].tolist()\n",
    "}\n",
    "\n",
    "bm25_path = bm25_dir / \"bm25_index.pkl\"\n",
    "with open(bm25_path, \"wb\") as f:\n",
    "    pickle.dump(bm25_data, f)\n",
    "\n",
    "print(f\"\\n✓ Saved BM25 index to {bm25_path}\")\n",
    "print(f\"  Size: {bm25_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4y44ov9mw77",
   "metadata": {},
   "source": [
    "## 3. Generate pairs with hard negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gedwtigoje",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:33.152057Z",
     "iopub.status.busy": "2025-10-26T02:19:33.152002Z",
     "iopub.status.idle": "2025-10-26T02:19:33.157446Z",
     "shell.execute_reply": "2025-10-26T02:19:33.157034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated 32 pairs for test artifact 10001\n",
      "  Positives: 2\n",
      "  Negatives: 30\n",
      "\n",
      "  Sample positive pair:\n",
      "    AU-6: Audit Review, Analysis, and Reporting. Regularly review and analyze audit logs; ...\n"
     ]
    }
   ],
   "source": [
    "TOP_K_CANDIDATES = 32  # Number of hard negative candidates to retrieve\n",
    "\n",
    "def generate_pairs_for_artifact(row, bm25_index, controls_df):\n",
    "    \"\"\"\n",
    "    Generate positive and hard negative pairs for a single artifact.\n",
    "    \n",
    "    Returns list of pair dicts with schema:\n",
    "    {artifact_id, artifact_text, evidence_type, control_id, control_text, family, label}\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    \n",
    "    # Parse gold controls\n",
    "    gold_controls = set()\n",
    "    if pd.notna(row[\"gold_controls\"]):\n",
    "        gold_controls = set(row[\"gold_controls\"].split(\";\"))\n",
    "    \n",
    "    # Retrieve top-K candidates using BM25\n",
    "    query_tokens = tokenize(row[\"text\"])\n",
    "    scores = bm25_index.get_scores(query_tokens)\n",
    "    top_indices = np.argsort(scores)[::-1][:TOP_K_CANDIDATES]\n",
    "    \n",
    "    # Collect all controls to include (golds + top-K candidates)\n",
    "    controls_to_include = set()\n",
    "    \n",
    "    # Add all gold controls as positives\n",
    "    for control_id in gold_controls:\n",
    "        controls_to_include.add(control_id)\n",
    "    \n",
    "    # Add top-K retrieved controls (will be negatives if not in gold)\n",
    "    for idx in top_indices:\n",
    "        control_id = controls_df.iloc[idx][\"control_id\"]\n",
    "        controls_to_include.add(control_id)\n",
    "    \n",
    "    # Create pairs\n",
    "    for control_id in controls_to_include:\n",
    "        control_row = controls_df[controls_df[\"control_id\"] == control_id].iloc[0]\n",
    "        \n",
    "        pair = {\n",
    "            \"artifact_id\": row[\"artifact_id\"],\n",
    "            \"artifact_text\": row[\"text\"],\n",
    "            \"evidence_type\": row[\"evidence_type\"],\n",
    "            \"control_id\": control_id,\n",
    "            \"control_text\": control_row[\"index_text\"],\n",
    "            \"family\": control_row[\"family\"],\n",
    "            \"label\": 1 if control_id in gold_controls else 0\n",
    "        }\n",
    "        pairs.append(pair)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Test on one artifact\n",
    "test_artifact = artifacts.iloc[0]\n",
    "test_pairs = generate_pairs_for_artifact(test_artifact, bm25, controls)\n",
    "print(f\"✓ Generated {len(test_pairs)} pairs for test artifact {test_artifact['artifact_id']}\")\n",
    "print(f\"  Positives: {sum(p['label'] == 1 for p in test_pairs)}\")\n",
    "print(f\"  Negatives: {sum(p['label'] == 0 for p in test_pairs)}\")\n",
    "print(f\"\\n  Sample positive pair:\")\n",
    "pos_pair = [p for p in test_pairs if p['label'] == 1][0]\n",
    "print(f\"    {pos_pair['control_id']}: {pos_pair['control_text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g03l3eacl2",
   "metadata": {},
   "source": [
    "## 4. Generate pairs for all partitions and save to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "s7bgpbk0s8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:33.158394Z",
     "iopub.status.busy": "2025-10-26T02:19:33.158331Z",
     "iopub.status.idle": "2025-10-26T02:19:35.115195Z",
     "shell.execute_reply": "2025-10-26T02:19:35.114764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing train partition...\n",
      "  1855 artifacts\n",
      "  ✓ Saved 59373 pairs to ../data/processed/pairs/train.jsonl\n",
      "    Positives: 3146, Negatives: 56227, Ratio: 0.053\n",
      "\n",
      "Processing dev partition...\n",
      "  365 artifacts\n",
      "  ✓ Saved 11683 pairs to ../data/processed/pairs/dev.jsonl\n",
      "    Positives: 581, Negatives: 11102, Ratio: 0.050\n",
      "\n",
      "Processing test partition...\n",
      "  354 artifacts\n",
      "  ✓ Saved 11332 pairs to ../data/processed/pairs/test.jsonl\n",
      "    Positives: 565, Negatives: 10767, Ratio: 0.050\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../data/processed/pairs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each partition separately\n",
    "partition_stats = {}\n",
    "\n",
    "for partition in [\"train\", \"dev\", \"test\"]:\n",
    "    print(f\"\\nProcessing {partition} partition...\")\n",
    "    \n",
    "    # Filter artifacts for this partition\n",
    "    partition_artifacts = artifacts[artifacts[\"partition\"] == partition]\n",
    "    print(f\"  {len(partition_artifacts)} artifacts\")\n",
    "    \n",
    "    # Generate pairs for all artifacts in this partition\n",
    "    all_pairs = []\n",
    "    for idx, row in partition_artifacts.iterrows():\n",
    "        pairs = generate_pairs_for_artifact(row, bm25, controls)\n",
    "        all_pairs.extend(pairs)\n",
    "    \n",
    "    # Save to JSONL\n",
    "    output_path = output_dir / f\"{partition}.jsonl\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for pair in all_pairs:\n",
    "            f.write(json.dumps(pair) + \"\\n\")\n",
    "    \n",
    "    # Collect statistics\n",
    "    n_positives = sum(p[\"label\"] == 1 for p in all_pairs)\n",
    "    n_negatives = sum(p[\"label\"] == 0 for p in all_pairs)\n",
    "    \n",
    "    partition_stats[partition] = {\n",
    "        \"n_artifacts\": len(partition_artifacts),\n",
    "        \"n_pairs\": len(all_pairs),\n",
    "        \"n_positives\": n_positives,\n",
    "        \"n_negatives\": n_negatives,\n",
    "        \"pos_ratio\": n_positives / len(all_pairs) if all_pairs else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ Saved {len(all_pairs)} pairs to {output_path}\")\n",
    "    print(f\"    Positives: {n_positives}, Negatives: {n_negatives}, Ratio: {partition_stats[partition]['pos_ratio']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ma7bzud3noh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:35.116211Z",
     "iopub.status.busy": "2025-10-26T02:19:35.116134Z",
     "iopub.status.idle": "2025-10-26T02:19:35.118978Z",
     "shell.execute_reply": "2025-10-26T02:19:35.118700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PAIR GENERATION SUMMARY\n",
      "================================================================================\n",
      "           n_artifacts  n_pairs  n_positives  n_negatives  pos_ratio\n",
      "partition                                                           \n",
      "train           1855.0  59373.0       3146.0      56227.0   0.052987\n",
      "dev              365.0  11683.0        581.0      11102.0   0.049730\n",
      "test             354.0  11332.0        565.0      10767.0   0.049859\n"
     ]
    }
   ],
   "source": [
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PAIR GENERATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_df = pd.DataFrame(partition_stats).T\n",
    "summary_df.index.name = \"partition\"\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91p6ul3liw",
   "metadata": {},
   "source": [
    "## 5. Acceptance checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "j9xx32zgw4m",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:19:35.120214Z",
     "iopub.status.busy": "2025-10-26T02:19:35.120145Z",
     "iopub.status.idle": "2025-10-26T02:19:35.180610Z",
     "shell.execute_reply": "2025-10-26T02:19:35.180294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACCEPTANCE CHECKS\n",
      "================================================================================\n",
      "\n",
      "✓ Check 1: No test artifact IDs in train/dev pair files\n",
      "  Test artifacts in train: 0\n",
      "  Test artifacts in dev: 0\n",
      "  Result: PASS\n",
      "\n",
      "✓ Check 2: Every train artifact has at least one positive pair\n",
      "  Train artifacts: 1855\n",
      "  Artifacts without positives: 0\n",
      "  Result: PASS\n",
      "\n",
      "================================================================================\n",
      "✅ ALL ACCEPTANCE CHECKS PASSED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ACCEPTANCE CHECKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check 1: No test artifacts appear in train/dev pair files\n",
    "print(\"\\n✓ Check 1: No test artifact IDs in train/dev pair files\")\n",
    "\n",
    "# Load all pair files and collect artifact IDs\n",
    "train_artifact_ids = set()\n",
    "dev_artifact_ids = set()\n",
    "test_artifact_ids = set()\n",
    "\n",
    "for partition, artifact_set in [(\"train\", train_artifact_ids), (\"dev\", dev_artifact_ids), (\"test\", test_artifact_ids)]:\n",
    "    pair_file = output_dir / f\"{partition}.jsonl\"\n",
    "    with open(pair_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            pair = json.loads(line)\n",
    "            artifact_set.add(pair[\"artifact_id\"])\n",
    "\n",
    "# Check for overlap\n",
    "test_in_train = test_artifact_ids & train_artifact_ids\n",
    "test_in_dev = test_artifact_ids & dev_artifact_ids\n",
    "\n",
    "check1 = len(test_in_train) == 0 and len(test_in_dev) == 0\n",
    "print(f\"  Test artifacts in train: {len(test_in_train)}\")\n",
    "print(f\"  Test artifacts in dev: {len(test_in_dev)}\")\n",
    "print(f\"  Result: {'PASS' if check1 else 'FAIL'}\")\n",
    "\n",
    "# Check 2: Every train artifact has at least one positive pair\n",
    "print(\"\\n✓ Check 2: Every train artifact has at least one positive pair\")\n",
    "\n",
    "train_pairs = []\n",
    "with open(output_dir / \"train.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        train_pairs.append(json.loads(line))\n",
    "\n",
    "# Group by artifact and check for positives\n",
    "artifact_has_positive = {}\n",
    "for pair in train_pairs:\n",
    "    aid = pair[\"artifact_id\"]\n",
    "    if aid not in artifact_has_positive:\n",
    "        artifact_has_positive[aid] = False\n",
    "    if pair[\"label\"] == 1:\n",
    "        artifact_has_positive[aid] = True\n",
    "\n",
    "artifacts_without_positives = [aid for aid, has_pos in artifact_has_positive.items() if not has_pos]\n",
    "check2 = len(artifacts_without_positives) == 0\n",
    "\n",
    "print(f\"  Train artifacts: {len(artifact_has_positive)}\")\n",
    "print(f\"  Artifacts without positives: {len(artifacts_without_positives)}\")\n",
    "print(f\"  Result: {'PASS' if check2 else 'FAIL'}\")\n",
    "\n",
    "if not check2:\n",
    "    print(f\"  Example artifacts without positives: {artifacts_without_positives[:5]}\")\n",
    "\n",
    "# Overall\n",
    "all_checks_passed = check1 and check2\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if all_checks_passed:\n",
    "    print(\"✅ ALL ACCEPTANCE CHECKS PASSED\")\n",
    "else:\n",
    "    print(\"❌ SOME ACCEPTANCE CHECKS FAILED\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
