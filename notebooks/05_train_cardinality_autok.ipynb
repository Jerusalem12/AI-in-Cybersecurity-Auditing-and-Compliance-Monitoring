{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 · Train Auto-K Cardinality Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "Learn to predict how many controls (1–3) to emit per artifact using calibrated scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "- `data/processed/pairs/train.jsonl` and `.../dev.jsonl` for score features.\n",
    "- Calibrated cross-encoder probabilities produced in Notebook 04."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "- `models/cardinality/model.pkl` containing the trained classifier.\n",
    "- `models/cardinality/feature_spec.json` documenting feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Generate per-artifact features: top calibrated probabilities s1–s4 (zero-padded), deltas (s1-s2, s2-s3), score entropy, and evidence_type one-hot vectors.\n",
    "2. Label each artifact with `min(3, |gold_controls|)` using the processed split file.\n",
    "3. Train a multi-class classifier (e.g., logistic regression or gradient boosting) on train artifacts.\n",
    "4. Evaluate on dev artifacts, capture accuracy, confusion matrix, and calibration sanity checks.\n",
    "5. Persist the fitted model and feature spec JSON for reproducible inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance Checks\n",
    "\n",
    "- Reported dev accuracy and confusion matrix summarize performance.\n",
    "- `models/cardinality/model.pkl` and `feature_spec.json` are written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expp8qale2j",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w5apup5vise",
   "metadata": {},
   "source": [
    "## 1. Load data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "o0n80n7yeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 2574 artifacts\n",
      "✓ Loaded cross-encoder model on mps\n",
      "✓ Loaded calibrator\n",
      "✓ Loaded 34 enhanced controls\n"
     ]
    }
   ],
   "source": [
    "# Load artifacts with splits and gold labels\n",
    "artifacts = pd.read_csv(\"../data/processed/artifacts_with_split.csv\", dtype={\"artifact_id\": str})\n",
    "print(f\"✓ Loaded {len(artifacts)} artifacts\")\n",
    "\n",
    "# Load cross-encoder model and calibrator\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "cross_encoder = CrossEncoder(\"../models/cross_encoder\", device=device)\n",
    "print(f\"✓ Loaded cross-encoder model on {device}\")\n",
    "\n",
    "# Load calibrator\n",
    "with open(\"../models/calibration/cross_iso.pkl\", \"rb\") as f:\n",
    "    calibrator = pickle.load(f)\n",
    "print(f\"✓ Loaded calibrator\")\n",
    "\n",
    "# Load enhanced controls\n",
    "controls = pd.read_csv(\"../data/processed/controls_enhanced.csv\", dtype=str)\n",
    "# index_text is already created in controls_enhanced.csv\n",
    "print(f\"✓ Loaded {len(controls)} enhanced controls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gz5hxtagml9",
   "metadata": {},
   "source": [
    "## 2. Generate calibrated scores for all artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mq3cd885j6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating calibrated scores for all artifacts...\n",
      "This may take several minutes...\n",
      "\n",
      "Processing train partition (1855 artifacts)...\n",
      "  Processed 50/1855...\n",
      "  Processed 100/1855...\n",
      "  Processed 150/1855...\n",
      "  Processed 200/1855...\n",
      "  Processed 250/1855...\n",
      "  Processed 300/1855...\n",
      "  Processed 350/1855...\n",
      "  Processed 400/1855...\n",
      "  Processed 450/1855...\n",
      "  Processed 500/1855...\n",
      "  Processed 550/1855...\n",
      "  Processed 600/1855...\n",
      "  Processed 650/1855...\n",
      "  Processed 700/1855...\n",
      "  Processed 750/1855...\n",
      "  Processed 800/1855...\n",
      "  Processed 850/1855...\n",
      "  Processed 900/1855...\n",
      "  Processed 950/1855...\n",
      "  Processed 1000/1855...\n",
      "  Processed 1050/1855...\n",
      "  Processed 1100/1855...\n",
      "  Processed 1150/1855...\n",
      "  Processed 1200/1855...\n",
      "  Processed 1250/1855...\n",
      "  Processed 1300/1855...\n",
      "  Processed 1350/1855...\n",
      "  Processed 1400/1855...\n",
      "  Processed 1450/1855...\n",
      "  Processed 1500/1855...\n",
      "  Processed 1550/1855...\n",
      "  Processed 1600/1855...\n",
      "  Processed 1650/1855...\n",
      "  Processed 1700/1855...\n",
      "  Processed 1750/1855...\n",
      "  Processed 1800/1855...\n",
      "  Processed 1850/1855...\n",
      "✓ Completed train partition\n",
      "\n",
      "Processing dev partition (365 artifacts)...\n",
      "  Processed 50/365...\n",
      "  Processed 100/365...\n",
      "  Processed 150/365...\n",
      "  Processed 200/365...\n",
      "  Processed 250/365...\n",
      "  Processed 300/365...\n",
      "  Processed 350/365...\n",
      "✓ Completed dev partition\n",
      "\n",
      "✓ Generated scores for 2220 artifacts\n"
     ]
    }
   ],
   "source": [
    "def get_calibrated_scores(artifact_text, controls_df, cross_encoder, calibrator, top_k=4):\n",
    "    \"\"\"\n",
    "    Get top-K calibrated scores for an artifact against all controls.\n",
    "    \"\"\"\n",
    "    # Create pairs\n",
    "    pairs = [[artifact_text, ctrl_text] for ctrl_text in controls_df[\"index_text\"]]\n",
    "    \n",
    "    # Get cross-encoder scores\n",
    "    scores = cross_encoder.predict(pairs, convert_to_numpy=True, show_progress_bar=False)\n",
    "    \n",
    "    # Convert to probabilities (sigmoid)\n",
    "    probs = 1 / (1 + np.exp(-scores))\n",
    "    \n",
    "    # Calibrate\n",
    "    calibrated_probs = calibrator.predict(probs)\n",
    "    \n",
    "    # Get top-K\n",
    "    top_indices = np.argsort(calibrated_probs)[::-1][:top_k]\n",
    "    top_scores = calibrated_probs[top_indices]\n",
    "    \n",
    "    return top_scores\n",
    "\n",
    "# Generate scores for all artifacts (this will take a while)\n",
    "print(\"Generating calibrated scores for all artifacts...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "artifact_scores = {}\n",
    "for partition in [\"train\", \"dev\"]:\n",
    "    partition_artifacts = artifacts[artifacts[\"partition\"] == partition]\n",
    "    print(f\"\\nProcessing {partition} partition ({len(partition_artifacts)} artifacts)...\")\n",
    "    \n",
    "    scores_list = []\n",
    "    for idx, row in partition_artifacts.iterrows():\n",
    "        top_scores = get_calibrated_scores(row[\"text\"], controls, cross_encoder, calibrator, top_k=4)\n",
    "        scores_list.append({\n",
    "            \"artifact_id\": row[\"artifact_id\"],\n",
    "            \"scores\": top_scores\n",
    "        })\n",
    "        \n",
    "        if (len(scores_list) % 50 == 0):\n",
    "            print(f\"  Processed {len(scores_list)}/{len(partition_artifacts)}...\")\n",
    "    \n",
    "    artifact_scores[partition] = scores_list\n",
    "    print(f\"✓ Completed {partition} partition\")\n",
    "\n",
    "print(f\"\\n✓ Generated scores for {sum(len(v) for v in artifact_scores.values())} artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2yzuz6tvwt8",
   "metadata": {},
   "source": [
    "## 3. Engineer features for cardinality prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "metkh8nxf9p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created feature matrices:\n",
      "  Train: (1855, 10), labels: 1855\n",
      "  Dev: (365, 10), labels: 365\n",
      "\n",
      "  Feature columns: ['s1', 's2', 's3', 's4', 'delta_12', 'delta_23', 'entropy', 'type_config', 'type_log', 'type_ticket']\n",
      "\n",
      "  Label distribution (train): [  0 723 973 159]\n",
      "  Label distribution (dev): [  0 156 202   7]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(scores, evidence_type, evidence_types=[\"config\", \"log\", \"ticket\"]):\n",
    "    \"\"\"\n",
    "    Extract features from calibrated scores.\n",
    "    \n",
    "    Features:\n",
    "    - s1, s2, s3, s4: Top 4 scores (zero-padded)\n",
    "    - delta_12: s1 - s2\n",
    "    - delta_23: s2 - s3\n",
    "    - entropy: Score entropy\n",
    "    - evidence_type one-hot encoding\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Top scores (zero-pad if less than 4)\n",
    "    for i in range(4):\n",
    "        features[f\"s{i+1}\"] = scores[i] if i < len(scores) else 0.0\n",
    "    \n",
    "    # Deltas\n",
    "    features[\"delta_12\"] = features[\"s1\"] - features[\"s2\"]\n",
    "    features[\"delta_23\"] = features[\"s2\"] - features[\"s3\"]\n",
    "    \n",
    "    # Entropy\n",
    "    valid_scores = scores[scores > 0]\n",
    "    if len(valid_scores) > 0:\n",
    "        entropy = -np.sum(valid_scores * np.log(valid_scores + 1e-10))\n",
    "    else:\n",
    "        entropy = 0.0\n",
    "    features[\"entropy\"] = entropy\n",
    "    \n",
    "    # Evidence type one-hot\n",
    "    for et in evidence_types:\n",
    "        features[f\"type_{et}\"] = 1 if evidence_type == et else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create feature matrix for train and dev\n",
    "def create_feature_matrix(artifacts_df, scores_dict, partition):\n",
    "    \"\"\"Create feature matrix and labels for a partition\"\"\"\n",
    "    features_list = []\n",
    "    labels = []\n",
    "    artifact_ids = []\n",
    "    \n",
    "    # Get scores for this partition\n",
    "    scores_data = {s[\"artifact_id\"]: s[\"scores\"] for s in scores_dict[partition]}\n",
    "    \n",
    "    for idx, row in artifacts_df[artifacts_df[\"partition\"] == partition].iterrows():\n",
    "        artifact_id = row[\"artifact_id\"]\n",
    "        \n",
    "        # Get features\n",
    "        if artifact_id in scores_data:\n",
    "            feat = extract_features(scores_data[artifact_id], row[\"evidence_type\"])\n",
    "            features_list.append(feat)\n",
    "            \n",
    "            # Label: min(3, number of gold controls)\n",
    "            n_gold = len(row[\"gold_controls\"].split(\";\")) if pd.notna(row[\"gold_controls\"]) else 0\n",
    "            label = min(3, n_gold)\n",
    "            labels.append(label)\n",
    "            artifact_ids.append(artifact_id)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    X = pd.DataFrame(features_list)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    return X, y, artifact_ids\n",
    "\n",
    "# Create train and dev sets\n",
    "X_train, y_train, train_ids = create_feature_matrix(artifacts, artifact_scores, \"train\")\n",
    "X_dev, y_dev, dev_ids = create_feature_matrix(artifacts, artifact_scores, \"dev\")\n",
    "\n",
    "print(f\"✓ Created feature matrices:\")\n",
    "print(f\"  Train: {X_train.shape}, labels: {len(y_train)}\")\n",
    "print(f\"  Dev: {X_dev.shape}, labels: {len(y_dev)}\")\n",
    "print(f\"\\n  Feature columns: {list(X_train.columns)}\")\n",
    "print(f\"\\n  Label distribution (train): {np.bincount(y_train)}\")\n",
    "print(f\"  Label distribution (dev): {np.bincount(y_dev)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364lkadgye",
   "metadata": {},
   "source": [
    "## 4. Train Auto-K classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8zbwxcdi7lo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Standardized features\n",
      "\n",
      "Training Auto-K classifier...\n",
      "✓ Training complete\n",
      "\n",
      "============================================================\n",
      "TRAINING RESULTS\n",
      "============================================================\n",
      "  Train accuracy: 0.6954\n",
      "  Dev accuracy:   0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikiyas/development/hodwa/crs/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_dev_scaled = scaler.transform(X_dev)\n",
    "\n",
    "print(\"✓ Standardized features\")\n",
    "\n",
    "# Train logistic regression classifier\n",
    "classifier = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_SEED,\n",
    "    class_weight=\"balanced\"  # Handle class imbalance\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Auto-K classifier...\")\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Training complete\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = classifier.predict(X_train_scaled)\n",
    "y_dev_pred = classifier.predict(X_dev_scaled)\n",
    "\n",
    "# Metrics\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "dev_acc = accuracy_score(y_dev, y_dev_pred)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Train accuracy: {train_acc:.4f}\")\n",
    "print(f\"  Dev accuracy:   {dev_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "qmht2xi9nud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONFUSION MATRIX (Dev Set)\n",
      "============================================================\n",
      "[[115  28  13]\n",
      " [ 48 113  41]\n",
      " [  0   1   6]]\n",
      "\n",
      "Rows: True labels, Columns: Predicted labels\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT (Dev Set)\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         k=1       0.71      0.74      0.72       156\n",
      "         k=2       0.80      0.56      0.66       202\n",
      "         k=3       0.10      0.86      0.18         7\n",
      "\n",
      "    accuracy                           0.64       365\n",
      "   macro avg       0.53      0.72      0.52       365\n",
      "weighted avg       0.74      0.64      0.68       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix and classification report\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CONFUSION MATRIX (Dev Set)\")\n",
    "print(f\"{'='*60}\")\n",
    "cm = confusion_matrix(y_dev, y_dev_pred)\n",
    "print(cm)\n",
    "print(f\"\\nRows: True labels, Columns: Predicted labels\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CLASSIFICATION REPORT (Dev Set)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(classification_report(y_dev, y_dev_pred, target_names=[\"k=1\", \"k=2\", \"k=3\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aw7vj5mprf",
   "metadata": {},
   "source": [
    "## 5. Save model and feature specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "garf0dnk2pf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved model to ../models/cardinality/model.pkl\n",
      "✓ Saved feature spec to ../models/cardinality/feature_spec.json\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../models/cardinality\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model and scaler together\n",
    "model_data = {\n",
    "    \"classifier\": classifier,\n",
    "    \"scaler\": scaler,\n",
    "    \"feature_columns\": list(X_train.columns)\n",
    "}\n",
    "\n",
    "model_path = output_dir / \"model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(f\"✓ Saved model to {model_path}\")\n",
    "\n",
    "# Save feature specification\n",
    "feature_spec = {\n",
    "    \"features\": [\n",
    "        {\"name\": \"s1\", \"description\": \"Top 1 calibrated score\"},\n",
    "        {\"name\": \"s2\", \"description\": \"Top 2 calibrated score\"},\n",
    "        {\"name\": \"s3\", \"description\": \"Top 3 calibrated score\"},\n",
    "        {\"name\": \"s4\", \"description\": \"Top 4 calibrated score\"},\n",
    "        {\"name\": \"delta_12\", \"description\": \"s1 - s2 (score gap)\"},\n",
    "        {\"name\": \"delta_23\", \"description\": \"s2 - s3 (score gap)\"},\n",
    "        {\"name\": \"entropy\", \"description\": \"Score entropy\"},\n",
    "        {\"name\": \"type_config\", \"description\": \"Evidence type: config (one-hot)\"},\n",
    "        {\"name\": \"type_log\", \"description\": \"Evidence type: log (one-hot)\"},\n",
    "        {\"name\": \"type_ticket\", \"description\": \"Evidence type: ticket (one-hot)\"}\n",
    "    ],\n",
    "    \"num_features\": len(X_train.columns),\n",
    "    \"classes\": [1, 2, 3],\n",
    "    \"class_names\": [\"k=1\", \"k=2\", \"k=3\"]\n",
    "}\n",
    "\n",
    "feature_spec_path = output_dir / \"feature_spec.json\"\n",
    "with open(feature_spec_path, \"w\") as f:\n",
    "    json.dump(feature_spec, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved feature spec to {feature_spec_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1vkxu0u9z0i",
   "metadata": {},
   "source": [
    "## 6. Acceptance checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4xzdps5h3nd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ACCEPTANCE CHECKS\n",
      "============================================================\n",
      "\n",
      "✓ Check 1: Dev accuracy and confusion matrix reported\n",
      "  Dev accuracy: 0.6411\n",
      "  Confusion matrix shape: (3, 3)\n",
      "  Result: PASS\n",
      "\n",
      "✓ Check 2: Model file saved\n",
      "  Path: ../models/cardinality/model.pkl\n",
      "  Exists: True\n",
      "  Size: 1.70 KB\n",
      "  Result: PASS\n",
      "\n",
      "✓ Check 3: Feature spec saved\n",
      "  Path: ../models/cardinality/feature_spec.json\n",
      "  Exists: True\n",
      "  Num features: 10\n",
      "  Result: PASS\n",
      "\n",
      "============================================================\n",
      "✅ ALL ACCEPTANCE CHECKS PASSED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ACCEPTANCE CHECKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check 1: Dev accuracy and confusion matrix reported\n",
    "check1 = dev_acc > 0\n",
    "print(f\"\\n✓ Check 1: Dev accuracy and confusion matrix reported\")\n",
    "print(f\"  Dev accuracy: {dev_acc:.4f}\")\n",
    "print(f\"  Confusion matrix shape: {cm.shape}\")\n",
    "print(f\"  Result: {'PASS' if check1 else 'FAIL'}\")\n",
    "\n",
    "# Check 2: Model file saved\n",
    "check2 = model_path.exists()\n",
    "print(f\"\\n✓ Check 2: Model file saved\")\n",
    "print(f\"  Path: {model_path}\")\n",
    "print(f\"  Exists: {check2}\")\n",
    "print(f\"  Size: {model_path.stat().st_size / 1024:.2f} KB\" if check2 else \"  Size: N/A\")\n",
    "print(f\"  Result: {'PASS' if check2 else 'FAIL'}\")\n",
    "\n",
    "# Check 3: Feature spec saved\n",
    "check3 = feature_spec_path.exists()\n",
    "print(f\"\\n✓ Check 3: Feature spec saved\")\n",
    "print(f\"  Path: {feature_spec_path}\")\n",
    "print(f\"  Exists: {check3}\")\n",
    "print(f\"  Num features: {feature_spec['num_features']}\" if check3 else \"  Num features: N/A\")\n",
    "print(f\"  Result: {'PASS' if check3 else 'FAIL'}\")\n",
    "\n",
    "# Overall\n",
    "all_checks_passed = check1 and check2 and check3\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_checks_passed:\n",
    "    print(\"✅ ALL ACCEPTANCE CHECKS PASSED\")\n",
    "else:\n",
    "    print(\"❌ SOME ACCEPTANCE CHECKS FAILED\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
